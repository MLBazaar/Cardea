{
    "name": "keras.preprocessing.text.Tokenizer",
    "author": "Carles Sala <carles@pythiac.com>",
    "documentation": "https://keras.io/preprocessing/text/#tokenizer",
    "description": "Text tokenization utility class.",
    "classifiers": {
        "type": "preprocessor",
        "subtype": "feature_extractor"
    },
    "modalities": ["text"],
    "primitive": "keras.preprocessing.text.Tokenizer",
    "fit": {
        "method": "fit_on_texts",
        "args": [
            {
                "name": "X",
                "keyword": "texts",
                "description": "list of strings, or list of list of strings.",
                "type": "list"
            }
        ]
    },
    "produce": {
        "method": "texts_to_sequences",
        "args": [
            {
                "name": "X",
                "keyword": "texts",
                "description": "list of strings, or list of list of strings.",
                "type": "list"
            }
        ],
        "output": [
            {
                "name": "X",
                "description": "list of sequences",
                "type": "list"
            }
        ]
    },
    "hyperparameters": {
        "fixed": {
            "filters": {
                "type": "str",
                "default": "!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\n"
            },
            "split": {
                "type": "str",
                "default": " "
            },
            "oov_token": {
                "type": "str",
                "default": null
            }
        },
        "tunable": {
            "num_words": {
                "type": "int",
                "default": null,
                "range": [1, 10000]
            },
            "lower": {
                "type": "bool",
                "default": true
            },
            "char_level": {
                "type": "bool",
                "default": false
            }
        }
    }
}
